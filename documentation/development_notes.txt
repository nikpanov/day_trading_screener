Project Structure in Visual Studio Code (VSC)

day_trading_screener/
│
├── config/
│   └── __init__.py
│
├── db/
│   ├── __init__.py
│   └── setup_schema.py
│
├── logs/
│   └── app.log
│
├── output/
│   └── (generated .xlsx reports)
│
├── tests/
│   ├── __init__.py
│   └── test_db_connection.py
│
├── .env
├── .gitignore
├── main.py
├── README.md
├── requirements.txt
├── pytest.ini
└── .venv/  (your virtual environment, not committed)



Step-by-Step: Set Up Git for Your ML Project
1. Create the Project Folder (if not already done)
2. Initialize Git run bash git init in side project directory
    git init
3. Create a .gitignore File
    # Python
    *.pyc
    __pycache__/
    .venv/
    venv/

    # Jupyter
    .ipynb_checkpoints/

    # Data & models
    data/raw/
    data/processed/
    models/

    # Environment
    .env

    # VSCode
    .vscode/

4. Commit Your Initial Code  
    git add .
    git commit -m "Initial commit: project structure and dependencies"

5. Create GitHub Repo (Manually or CLI)
Manual:
    Go to https://github.com/new
    Create a public or private repo (e.g., bullish_ml_project)
    Do not check "Initialize with README" (since we already have files)

Link Remote and Push
    git remote add origin https://github.com/YOUR_USERNAME/bullish_ml_project.git
    git branch -M main
    git push -u origin main

6. Add a README.md    
    # Day Trading Screener

    A day trading stock screener using real-time market data and PostgreSQL.

    ## Features
    - Core and technical filters for intraday momentum
    - PostgreSQL schema for screener runs, results, technicals, and caching
    - Output to XLSX for inspection or reporting
    - Modular and testable with pytest

    ## Setup
    1. Create `.env` file based on `.env.example`
    2. Create a virtual environment:
    python -m venv .venv
    .venv/Scripts/activate 
    pip install -r requirements.txt
    3. Run the schema setup

    4. Run tests

Create requirements.txt and install libraries to the Environment   
Recommended requirements.txt for Your Project
    pandas
    numpy
    requests
    scikit-learn
    xgboost
    ta
    matplotlib
    seaborn
    python-dotenv

pip install -r requirements.txt

What Each Package Is For
| Package         | Purpose                                                         |
| --------------- | --------------------------------------------------------------- |
| `pandas`        | Data handling, DataFrame operations                             |
| `numpy`         | Numerical operations, arrays                                    |
| `requests`      | Fetch data from the FMP API                                     |
| `scikit-learn`  | ML models: LogisticRegression, RandomForest, evaluation metrics |
| `xgboost`       | Gradient Boosting model, often superior for tabular data        |
| `ta`            | Technical Analysis indicators (RSI, MACD, ADX, etc.)            |
| `matplotlib`    | Visualization                                                   |
| `seaborn`       | Statistical data plotting (correlations, distributions)         |
| `python-dotenv` | Load API keys from a `.env` file safely                         |



To Run  Project in bash
PYTHONPATH=. python main.py

You should see:
    FMP download
    data/processed/AAPL_labeled.csv created (or another ticker)
    A column bullish_label with 1 where the price rose ≥10% in 10 days

Guaranteed Bullish Examples (Last Year) -----------------------    

NVDA (NVIDIA)
📈 Exploded from ~$150 (Jan 2023) to over $900 by mid-2024
Many 10%+ jumps in short spans, especially:
🔹 Feb–Mar 2024
🔹 May 2024 (earnings rally)

2. SMCI (Super Micro Computer)
🚀 One of the fastest-growing AI hardware stocks
Multiple +20% moves in 3–5 day windows in early 2024

3. META (Meta Platforms)
Sharp growth after positive earnings and AI announcements
Look at Jan–Feb 2024

4. TSLA (Tesla)
Volatile but often has sharp upside moves
Check Oct 2023 and Feb 2024

How Much History Do You Really Need? -----------------------------
Use Case	                Recommended History
Manual test & debugging	    250–500 days (1 year)
Training a real ML model	2–5 years (≈500–1,250 trading days)
Long-term pattern analysis	5+ years

📝 There are ~252 trading days in a year, so 1250 ≈ 5 years

Stage 2: Compute technical indicators like RSI, MACD, SMA, etc. using the ta library and add those as features.
What Stage 2 Includes:
Input:
    The labeled dataset from Stage 1: price history + bullish_label
    Each row = a stock on a date
Process:
    Compute indicators like RSI, MACD, 50/200-day SMA, Volume trends, etc.
    Add each as a column (rsi_14, macd_signal_diff, sma_50_over_sma_200, etc.)
    Keep the label (bullish_label) as the target
    📌 The model will learn how to weigh them — no more static thresholds or human-picked weights.
Output:
    A DataFrame with one row per date per stock:
    date | close | rsi_14 | macd_diff | sma_50 | sma_200 | ... | bullish_label

Why This Works Better    
| Traditional Rules         | ML-Based Approach                        |
| ------------------------- | ---------------------------------------- |
| You define rules manually | Model learns patterns from the data      |
| Hard to tune weights      | Model optimizes importance automatically |
| Doesn’t adapt to market   | Can retrain as market behavior evolves   |

So instead of saying:
    “Bullish = RSI < 30 and MACD > 0 and Price > 200-SMA”
…we say:
    “Here are RSI, MACD, SMA, and price — let the model learn what matters.”

Stage 2 Goals -------------------------------------- accomplished!
    Compute indicators with the ta library (technical analysis)
    Merge them into your labeled dataset
    Clean & normalize the features
    Save the final training dataset    

=================== Current
✅ Screener Operation Workflow
🕒 1. Scheduled Execution
The screener is scheduled to run every 15 minutes during trading hours.

Executed by scheduler.py using run_screener(...).

Option to tweak interval using --interval.

📥 2. Initial Cache Population
At first (startup or once a day), cache is filled:

✅ screener_cache: stores fundamentals (beta, market cap, etc.)

✅ premarket_cache: stores pre-market % change

These are fetched in chunks (with limit) to reduce API load.

🔁 3. Reuse + Refresh on Subsequent Runs
Each run:

Pulls ticker batch using rotation strategy

Fetches new technical indicators

Reuses screener_cache + premarket_cache unless expired or missing

📄 Output
💾 Database
✅ Every screener run is stored in PostgreSQL (screener_run, screener_result)

📊 Excel Files

========== Unit tests succeded.
| Entry Point                        | Description                       |
| ---------------------------------- | --------------------------------- |
| `main.py`                          | One-time screener run             |
| `scheduler.py`                     | Periodic runs during market hours |
| `db/ticker_rotation_import_fmp.py` | Ticker import from FMP            |
| `db/backtester.py`                 | Historical backtest execution     |

for production run:

Open Task Scheduler (search in Start Menu)
Create a new task:
Go to Action > Create Basic ask
Name: Day Trading Screener
Trigger: Daily, 9:30 AM (set to run only on weekdays)
Action: Start a program
Set the program to run:
"F:\Nick\My Code\trading\day_trading_screener\start_scheduler.bat"
Start in:
F:\Nick\My Code\trading\day_trading_screener

===============================================
Single Run Test
➡️ Run main.py manually or in test mode to simulate one full screener cycle.
🔁 It:
Pulls tickers from rotation
Fetches fundamentals & technicals
Applies filters
Logs results
💾 Saves to:
PostgreSQL tables (screener_run, stock_result)
Excel (output/screener_results/...xlsx)

💻 Command:
bash
cd "F:/Nick/My Code/trading/day_trading_screener"
python main.py --debug --limit 50 --tighten

Comments for switches: 
--debug → sets logging to DEBUG level
--limit 25 → analyze 25 tickers instead of 50
--tighten → enables optional filters (beta > 1, market cap > 2B, etc.)
=================================================
 Continuous Run (Production Mode)
➡️ Run scheduler.py via Task Scheduler to automatically:
Start at 9:30 AM ET
Loop through screener runs
Adjust interval during market hours (15/30/15 mins)
Sleep if market closed

🧠 Uses:
run_screener() just like main.py
Logging to logs/app.log
Dynamic interval control
Automatically saves every result to DB + Excel
🔁 Automatically loops all day until 4:00 PM ET
*********************************************************** NEXT ROUND *************************
🔧 Core Execution Scripts
main.py – likely the entry point for running the screener.

scheduler.py – manages execution timing during market hours.

runner/screener_runner.py – core orchestration logic for running the screener.

🧠 Screener Logic & Utilities
utils/filters.py – implements is_bullish and optional filters.

utils/exporter.py – handles Excel output.

utils/logger.py – custom logging configuration.

🌐 API Interaction
api/fmp_client.py – interfaces with Financial Modeling Prep (FMP) API.

🛢️ Database Integration
db/writer.py – saves scan results and run metadata.

db/cache.py – manages caching of API results.

db/setup_schema.py – initializes schema if needed.

db/ticker_rotation_import_*.py – ticker list importers (CSV and FMP).

✉️ Email Notifications
emailer/notify.py – email functionality (e.g., alerts for bullish tickers).

🧪 Testing
tests/ – unit tests for every major module.

⚙️ Configuration
config/settings.py – defines constants, config variables.

.venv/ – virtual environment (ignored in analysis).

🧾 Backtesting
backtester.py, backtester_old.py – historical performance testing.
--------------------------------------------------------------------------
 main.py – Entry Point
This script coordinates the screener execution process. Key responsibilities:

Configures CLI argument parsing using argparse:
--limit: Number of tickers to screen (default: 50) full run --2500
--use-optional-filters: Toggles additional filters
--debug: Enables verbose logging

Calls run_screener(...) with the parsed options:
run_screener(limit=args.limit, use_optional_filters=args.use_optional_filters, log_level=log_level)

🔹 screener_runner.py – Core Orchestration
This is the main workflow engine. Key components:

🔧 Setup
Imports:
API: fetch_core_screener, fetch_technicals, fetch_fundamentals, fetch_pre_market_change
Filters: is_bullish
DB: save_run_and_results, upsert_screener_cache, upsert_premarket_cache
Export: export_screener_results_to_excel
Logger setup via setup_logger()
now_et() handles Eastern Time using pytz

⚙️ run_screener(...) Logic
Start Time & Logging
Logs current time and options.
Fetch Core Screener Data
From FMP using fetch_core_screener(limit)
Optionally Apply Custom Filters
If use_optional_filters is True
Parallel Processing (ThreadPool)
Iterates over tickers using ThreadPoolExecutor

Each worker:
Fetches pre-market, technical, and fundamental data
Caches them
Runs is_bullish(...)
Collects results
Persistence
Saves to DB via save_run_and_results(...)
Exports Excel with timestamped filename
Summary Logging
Number of bullish tickers detected
Execution time

✅ Current Strengths
Clean modular structure with separation of concerns.
Multi-threaded ticker evaluation.
Flexible CLI + logger integration.
Results stored and exported properly.

⚠️ Bottlenecks & Next Steps
The current system:
Hits the FMP API per ticker in parallel (risks throttling/ban)
Lacks rate limiting, retry logic, or API batch usage (where possible)
Does not chunk or paginate the ticker list

Would you like a proposal and code changes for:
Throttling (rate limiting) per API type?
Chunking (batch mode) for initial core screener fetch and analysis loop?
Retry/backoff logic?

We can tackle them in sequence. 
Summary of Step 1 – Throttling
You now have:
Per-function RateLimiters in fmp_client.py
Protection against exceeding FMP’s rate limits
Compatibility with multi-threaded execution via ThreadPoolExecutor

=============== Throtteling
Starter plan 5 per sec, 300 per minute
RateLimiter changed from 5,1 to 4, 1 in fmp_client

 ******************* Great — your objective is daily trading, which means: ****************************

You want to enter trades intraday, ideally soon after the market opens.
Your goal is to spot bullish setups forming in real time based on your multi-factor strategy.
You're not scanning 10K penny stocks — your pipeline already filters intelligently.

✅ Recommended Screener Execution Algorithm for Daily Trading
📅 Market Day Timeline (U.S. Eastern Time)
Phase	        Time (ET)	    Goal
Pre-market	    8:00–9:30	    Prep watchlist (optional)
Opening range	9:30–10:30	🟢 Primary opportunity window
Midday/lull	    11:00–13:30	😴 Low momentum, avoid overtrading
Power hour	    15:00–16:00	🔁 Re-check for afternoon moves

---------
🔁 Screener Algorithm Flow

🔹 Step 1: Full Screener at Market Open (9:30 AM)
Purpose: Identify bullish setups across entire universe (NASDAQ + NYSE).
Inputs: All 2400–3000 tickers from core screener.
Output: Flag bullish candidates + store top ~200 in a watchlist cache.
Run time: ~60 minutes with throttling.
✅ This creates your morning shortlist.

🔹 Step 2: Watchlist Screener Every 15 Min (10:00–12:00)
Purpose: Track technical evolution of ~200-300 tickers.
Inputs: Watchlist from Step 1.
Logic:
Re-check only technicals (not fundamentals).
Use updated prices, volume, RSI, EMA, MACD.
Output: New bullish signals as they form intraday.
✅ This allows you to act during the morning trend continuation phase.

🔹 Step 3: Midday Pause or Sparse Monitoring (12:00–13:30)
Option A: Pause screener (low volume phase).
Option B: Run hourly on high volatility subset.
✅ Prevents overtrading in low-momentum periods.

🔹 Step 4: Optional Afternoon Sweep (15:00–15:45)
Final full or watchlist scan to catch late breakouts.
Could re-check tickers that were “almost bullish” earlier.
✅ Useful for EOD entries or confirming ongoing positions.

Summary Workflow
Time Range	Action	Ticker Count
09:30–10:30	🧠 Full scan (universe)	2400–3000
Every 15 min	⏱️ Watchlist scan (bullish only)	200–300
12:00–13:30	💤 (pause or reduce to 1/hour)	50–100
15:00–15:45	🔁 Final full/partial scan (optional)	200–500

Bonus: Watchlist Prioritization
Prioritize watchlist tickers using:
Pre-market movers
High volume % gainers
Beta > 1.5
Volatility clusters (ATR, Bollinger breakout)
Past bullish success rate
============= Immplementation
📄 Download scheduler.py

This version replaces the older one and implements:
🧠 One-time full scan at market open (09:30–10:30)
⏱️ Watchlist scans every 15 minutes (10:30–12:00 and 13:30–15:00)
😴 Hourly scans during lunch (12:00–13:30)
🔁 Optional final full scan (15:00–15:45)
✅ All times are in US Eastern time with log output to logs/scheduler.log

