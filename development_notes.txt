Project Structure in Visual Studio Code (VSC)

day_trading_screener/
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ setup_schema.py
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ app.log
â”‚
â”œâ”€â”€ output/
â”‚   â””â”€â”€ (generated .xlsx reports)
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_db_connection.py
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ main.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pytest.ini
â””â”€â”€ .venv/  (your virtual environment, not committed)



Step-by-Step: Set Up Git for Your ML Project
1. Create the Project Folder (if not already done)
2. Initialize Git run bash git init in side project directory
    git init
3. Create a .gitignore File
    # Python
    *.pyc
    __pycache__/
    .venv/
    venv/

    # Jupyter
    .ipynb_checkpoints/

    # Data & models
    data/raw/
    data/processed/
    models/

    # Environment
    .env

    # VSCode
    .vscode/

4. Commit Your Initial Code  
    git add .
    git commit -m "Initial commit: project structure and dependencies"

5. Create GitHub Repo (Manually or CLI)
Manual:
    Go to https://github.com/new
    Create a public or private repo (e.g., bullish_ml_project)
    Do not check "Initialize with README" (since we already have files)

Link Remote and Push
    git remote add origin https://github.com/YOUR_USERNAME/bullish_ml_project.git
    git branch -M main
    git push -u origin main

6. Add a README.md    
    # Day Trading Screener

    A day trading stock screener using real-time market data and PostgreSQL.

    ## Features
    - Core and technical filters for intraday momentum
    - PostgreSQL schema for screener runs, results, technicals, and caching
    - Output to XLSX for inspection or reporting
    - Modular and testable with pytest

    ## Setup
    1. Create `.env` file based on `.env.example`
    2. Create a virtual environment:
    python -m venv .venv
    .venv/Scripts/activate 
    pip install -r requirements.txt
    3. Run the schema setup

    4. Run tests

Create requirements.txt and install libraries to the Environment   
Recommended requirements.txt for Your Project
    pandas
    numpy
    requests
    scikit-learn
    xgboost
    ta
    matplotlib
    seaborn
    python-dotenv

pip install -r requirements.txt

What Each Package Is For
| Package         | Purpose                                                         |
| --------------- | --------------------------------------------------------------- |
| `pandas`        | Data handling, DataFrame operations                             |
| `numpy`         | Numerical operations, arrays                                    |
| `requests`      | Fetch data from the FMP API                                     |
| `scikit-learn`  | ML models: LogisticRegression, RandomForest, evaluation metrics |
| `xgboost`       | Gradient Boosting model, often superior for tabular data        |
| `ta`            | Technical Analysis indicators (RSI, MACD, ADX, etc.)            |
| `matplotlib`    | Visualization                                                   |
| `seaborn`       | Statistical data plotting (correlations, distributions)         |
| `python-dotenv` | Load API keys from a `.env` file safely                         |



To Run  Project in bash
PYTHONPATH=. python main.py

You should see:
    FMP download
    data/processed/AAPL_labeled.csv created (or another ticker)
    A column bullish_label with 1 where the price rose â‰¥10% in 10 days

Guaranteed Bullish Examples (Last Year) -----------------------    

NVDA (NVIDIA)
ğŸ“ˆ Exploded from ~$150 (Jan 2023) to over $900 by mid-2024
Many 10%+ jumps in short spans, especially:
ğŸ”¹ Febâ€“Mar 2024
ğŸ”¹ May 2024 (earnings rally)

2. SMCI (Super Micro Computer)
ğŸš€ One of the fastest-growing AI hardware stocks
Multiple +20% moves in 3â€“5 day windows in early 2024

3. META (Meta Platforms)
Sharp growth after positive earnings and AI announcements
Look at Janâ€“Feb 2024

4. TSLA (Tesla)
Volatile but often has sharp upside moves
Check Oct 2023 and Feb 2024

How Much History Do You Really Need? -----------------------------
Use Case	                Recommended History
Manual test & debugging	    250â€“500 days (1 year)
Training a real ML model	2â€“5 years (â‰ˆ500â€“1,250 trading days)
Long-term pattern analysis	5+ years

ğŸ“ There are ~252 trading days in a year, so 1250 â‰ˆ 5 years

Stage 2: Compute technical indicators like RSI, MACD, SMA, etc. using the ta library and add those as features.
What Stage 2 Includes:
Input:
    The labeled dataset from Stage 1: price history + bullish_label
    Each row = a stock on a date
Process:
    Compute indicators like RSI, MACD, 50/200-day SMA, Volume trends, etc.
    Add each as a column (rsi_14, macd_signal_diff, sma_50_over_sma_200, etc.)
    Keep the label (bullish_label) as the target
    ğŸ“Œ The model will learn how to weigh them â€” no more static thresholds or human-picked weights.
Output:
    A DataFrame with one row per date per stock:
    date | close | rsi_14 | macd_diff | sma_50 | sma_200 | ... | bullish_label

Why This Works Better    
| Traditional Rules         | ML-Based Approach                        |
| ------------------------- | ---------------------------------------- |
| You define rules manually | Model learns patterns from the data      |
| Hard to tune weights      | Model optimizes importance automatically |
| Doesnâ€™t adapt to market   | Can retrain as market behavior evolves   |

So instead of saying:
    â€œBullish = RSI < 30 and MACD > 0 and Price > 200-SMAâ€
â€¦we say:
    â€œHere are RSI, MACD, SMA, and price â€” let the model learn what matters.â€

Stage 2 Goals -------------------------------------- accomplished!
    Compute indicators with the ta library (technical analysis)
    Merge them into your labeled dataset
    Clean & normalize the features
    Save the final training dataset    

=================== Current
âœ… Screener Operation Workflow
ğŸ•’ 1. Scheduled Execution
The screener is scheduled to run every 15 minutes during trading hours.

Executed by scheduler.py using run_screener(...).

Option to tweak interval using --interval.

ğŸ“¥ 2. Initial Cache Population
At first (startup or once a day), cache is filled:

âœ… screener_cache: stores fundamentals (beta, market cap, etc.)

âœ… premarket_cache: stores pre-market % change

These are fetched in chunks (with limit) to reduce API load.

ğŸ” 3. Reuse + Refresh on Subsequent Runs
Each run:

Pulls ticker batch using rotation strategy

Fetches new technical indicators

Reuses screener_cache + premarket_cache unless expired or missing

ğŸ“„ Output
ğŸ’¾ Database
âœ… Every screener run is stored in PostgreSQL (screener_run, screener_result)

ğŸ“Š Excel Files

========== Unit tests succeded.
| Entry Point                        | Description                       |
| ---------------------------------- | --------------------------------- |
| `main.py`                          | One-time screener run             |
| `scheduler.py`                     | Periodic runs during market hours |
| `db/ticker_rotation_import_fmp.py` | Ticker import from FMP            |
| `db/backtester.py`                 | Historical backtest execution     |

for production run:

Open Task Scheduler (search in Start Menu)
Create a new task:
Go to Action > Create Basic ask
Name: Day Trading Screener
Trigger: Daily, 9:30 AM (set to run only on weekdays)
Action: Start a program
Set the program to run:
"F:\Nick\My Code\trading\day_trading_screener\start_scheduler.bat"
Start in:
F:\Nick\My Code\trading\day_trading_screener

===============================================
Single Run Test
â¡ï¸ Run main.py manually or in test mode to simulate one full screener cycle.
ğŸ” It:
Pulls tickers from rotation
Fetches fundamentals & technicals
Applies filters
Logs results
ğŸ’¾ Saves to:
PostgreSQL tables (screener_run, stock_result)
Excel (output/screener_results/...xlsx)

ğŸ’» Command:
bash
cd "F:/Nick/My Code/trading/day_trading_screener"
python main.py --debug --limit 50 --tighten

Comments for switches: 
--debug â†’ sets logging to DEBUG level
--limit 25 â†’ analyze 25 tickers instead of 50
--tighten â†’ enables optional filters (beta > 1, market cap > 2B, etc.)
=================================================
 Continuous Run (Production Mode)
â¡ï¸ Run scheduler.py via Task Scheduler to automatically:
Start at 9:30 AM ET
Loop through screener runs
Adjust interval during market hours (15/30/15 mins)
Sleep if market closed

ğŸ§  Uses:
run_screener() just like main.py
Logging to logs/app.log
Dynamic interval control
Automatically saves every result to DB + Excel
ğŸ” Automatically loops all day until 4:00 PM ET
*********************************************************** NEXT ROUND *************************
ğŸ”§ Core Execution Scripts
main.py â€“ likely the entry point for running the screener.

scheduler.py â€“ manages execution timing during market hours.

runner/screener_runner.py â€“ core orchestration logic for running the screener.

ğŸ§  Screener Logic & Utilities
utils/filters.py â€“ implements is_bullish and optional filters.

utils/exporter.py â€“ handles Excel output.

utils/logger.py â€“ custom logging configuration.

ğŸŒ API Interaction
api/fmp_client.py â€“ interfaces with Financial Modeling Prep (FMP) API.

ğŸ›¢ï¸ Database Integration
db/writer.py â€“ saves scan results and run metadata.

db/cache.py â€“ manages caching of API results.

db/setup_schema.py â€“ initializes schema if needed.

db/ticker_rotation_import_*.py â€“ ticker list importers (CSV and FMP).

âœ‰ï¸ Email Notifications
emailer/notify.py â€“ email functionality (e.g., alerts for bullish tickers).

ğŸ§ª Testing
tests/ â€“ unit tests for every major module.

âš™ï¸ Configuration
config/settings.py â€“ defines constants, config variables.

.venv/ â€“ virtual environment (ignored in analysis).

ğŸ§¾ Backtesting
backtester.py, backtester_old.py â€“ historical performance testing.
--------------------------------------------------------------------------
 main.py â€“ Entry Point
This script coordinates the screener execution process. Key responsibilities:

Configures CLI argument parsing using argparse:
--limit: Number of tickers to screen (default: 50) full run --2500
--use-optional-filters: Toggles additional filters
--debug: Enables verbose logging

Calls run_screener(...) with the parsed options:
run_screener(limit=args.limit, use_optional_filters=args.use_optional_filters, log_level=log_level)

ğŸ”¹ screener_runner.py â€“ Core Orchestration
This is the main workflow engine. Key components:

ğŸ”§ Setup
Imports:
API: fetch_core_screener, fetch_technicals, fetch_fundamentals, fetch_pre_market_change
Filters: is_bullish
DB: save_run_and_results, upsert_screener_cache, upsert_premarket_cache
Export: export_screener_results_to_excel
Logger setup via setup_logger()
now_et() handles Eastern Time using pytz

âš™ï¸ run_screener(...) Logic
Start Time & Logging
Logs current time and options.
Fetch Core Screener Data
From FMP using fetch_core_screener(limit)
Optionally Apply Custom Filters
If use_optional_filters is True
Parallel Processing (ThreadPool)
Iterates over tickers using ThreadPoolExecutor

Each worker:
Fetches pre-market, technical, and fundamental data
Caches them
Runs is_bullish(...)
Collects results
Persistence
Saves to DB via save_run_and_results(...)
Exports Excel with timestamped filename
Summary Logging
Number of bullish tickers detected
Execution time

âœ… Current Strengths
Clean modular structure with separation of concerns.
Multi-threaded ticker evaluation.
Flexible CLI + logger integration.
Results stored and exported properly.

âš ï¸ Bottlenecks & Next Steps
The current system:
Hits the FMP API per ticker in parallel (risks throttling/ban)
Lacks rate limiting, retry logic, or API batch usage (where possible)
Does not chunk or paginate the ticker list

Would you like a proposal and code changes for:
Throttling (rate limiting) per API type?
Chunking (batch mode) for initial core screener fetch and analysis loop?
Retry/backoff logic?

We can tackle them in sequence. 
Summary of Step 1 â€“ Throttling
You now have:
Per-function RateLimiters in fmp_client.py
Protection against exceeding FMPâ€™s rate limits
Compatibility with multi-threaded execution via ThreadPoolExecutor
